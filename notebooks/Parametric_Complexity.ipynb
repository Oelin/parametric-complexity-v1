{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parametric Complexity"
      ],
      "metadata": {
        "id": "kCcWi6lr8wJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction"
      ],
      "metadata": {
        "id": "G4y11K8o8zDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *parametric complexity* of a model family $\\mathcal{M}$ is a measure of how much information it tends to *memorise* when fitted using a particular estimator. In the case of MLE, it measures how susceptible the *most likley* model in the family is to overfitting. Then it can be used to make sound comparisons between the *probabilities* of different model families as follows. Let\n"
      ],
      "metadata": {
        "id": "Z1n3_w4Y818O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### $$L_{\\text{nml}}(\\mathcal{M}|D) = L_{M^*}(D) + L_\\mathcal{M}(\\mathcal{M})$$"
      ],
      "metadata": {
        "id": "HnK8tuNpK3ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "where:\n",
        "\n",
        "- $\\mathcal{M}$ is a model family amoung some set of candiates $\\mathcal{M}_1,\\dots,\\mathcal{M}_n$.\n",
        "\n",
        "- $D$ is a dataset from some family $\\mathcal{D}$.\n",
        "\n",
        "- $L_{\\text{nml}}$ is the *posterior* length of $\\mathcal{M}$ given $D$.\n",
        "\n",
        "- $L_{M^*}$ is the *likelihood* length of $D$ under the MLE estimate $M^*$. \n",
        "\n",
        "- $L_\\mathcal{M}$ is the *prior* length of $\\mathcal{M}$, i.e. its parametric complexity."
      ],
      "metadata": {
        "id": "J3Cl8fTBK3dq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Then the *most probable* model family is the one with shortest posterior length. To compute this length, we first need to compute $L_{M^*}$ and $L_\\mathcal{M}$. Luckily, this is rather straightforward and avoids the arbitrariness of crude MDL.\n"
      ],
      "metadata": {
        "id": "A22KHs53K3fX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute $L_{M^*}$, we simply find the MLE esimate $M^* \\in \\mathcal{M}$ and then compute $L_{M^*}(D) = -\\log_2 p_{M^*}(D)$. In other words, we calculate how much the MLE can compress the dataset."
      ],
      "metadata": {
        "id": "VdEzuYKqK3hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute $L_{\\mathcal{M}}$, we use the following algorithm:\n",
        "\n",
        "1. Pick a dataset from $\\mathcal{D}$, such that each data point is chosen uniformly at random. Neccessarily, the chance that at least $k$ bits can be removed from this dataset is exponentially small in $k$.\n",
        "\n",
        "2. Compute $L_{M^*}$ for this dataset and subtract it from the dataset's original size in bits. Since the dataset cannot feasibly be compressed, this measures how much information is simply *memorised* in $M^*$.\n",
        "\n",
        "3. Repeat steps 1-2 several times to obtain an average for how many bits are memorised.\n",
        "\n",
        "4. Return this average as the parametric complexity of $\\mathcal{M}$.\n",
        "\n",
        "> Note 1: for step 2, we assume that the number of bits removed from the dataset is sufficiently large, such that the probability that those bits *were memorised* is very close to 1. For example, if 50 bits are removed, the probability that they were memorised is $1 - 2^{-50} =  0.9999999999999991$. It's exeedingly likely that those bits were simply transfered to the model rather than genuinly compressed.\n",
        ">\n",
        "> Note 2: this algorithm estimates parametric complexity w.r.t. a particular dataset family $\\mathcal{D}$. This is a specification for how many features and examples are in the dataset. It's important that $D \\in \\mathcal{D}$ when we calculate $L_M^*$, i.e. it must have the same number of features and examples. "
      ],
      "metadata": {
        "id": "u3N9qJLHLk8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List"
      ],
      "metadata": {
        "id": "wH9PE6KwNAFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U8nKWn66zF1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQvtix0AJHBo"
      },
      "outputs": [],
      "source": [
        "class Sampler:\n",
        "\n",
        "    def sample(self, length: int) -> List:\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "\n",
        "    def fit(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def score(self):\n",
        "        raise NotImplementedError()"
      ],
      "metadata": {
        "id": "mnYnve-LKlkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binaryClassifierComplexity(model: Model, sampler: Sampler, trials: int = 1000, samples: int = 1000, return_scores=False):\n",
        "    \"\"\"\n",
        "    Computes parametric complexity for biniary classifiers.\n",
        "    \"\"\"\n",
        "\n",
        "    scores: List[float] = []\n",
        "\n",
        "    for i in range(trials):\n",
        "        \n",
        "        dataset = sampler.sample(samples)\n",
        "        hypothesis = model.fit(*dataset)\n",
        "\n",
        "        probits = model.predict_proba(dataset[0])\n",
        "        probits_0 = probits[:,0]\n",
        "        probits_1 = probits[:,1]\n",
        "\n",
        "        probits = (probits_0 * (dataset[1] == 0)) + (probits_1 * (dataset[1] == 1))\n",
        "        logits = -np.log2(probits)\n",
        "\n",
        "        compressed_size = np.sum(logits)\n",
        "        scores.append(samples - compressed_size)\n",
        "    \n",
        "    if return_scores:\n",
        "        return scores\n",
        "    \n",
        "    return np.mean(scores)"
      ],
      "metadata": {
        "id": "wB694HMJLXDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6lfGggZbMqb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionSampler(Sampler):\n",
        "\n",
        "    def sample(self, length):\n",
        "\n",
        "        X = np.random.rand(length, 1)\n",
        "        y = (np.random.rand(length) < 0.5).astype(int)\n",
        "\n",
        "        return (X, y)"
      ],
      "metadata": {
        "id": "CIEbQp-GN420"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = LogisticRegressionSampler()\n",
        "model = LogisticRegression()"
      ],
      "metadata": {
        "id": "Uydwml34PAWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model_10 = MLPClassifier(hidden_layer_sizes = (10,), max_iter=8000)\n",
        "model_100 = MLPClassifier(hidden_layer_sizes = (100,), max_iter=3000)\n",
        "model_100_10 = MLPClassifier(hidden_layer_sizes = (100,10), max_iter=10_000)\n",
        "model_100_100 = MLPClassifier(hidden_layer_sizes = (100,100), max_iter=10_000)\n",
        "model_500_500 = MLPClassifier(hidden_layer_sizes = (500,500), max_iter=10_000)\n",
        "model_tree = DecisionTreeClassifier(max_depth=5)"
      ],
      "metadata": {
        "id": "l7_1p5vYP4_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binaryClassifierComplexity(model_10, sampler, trials=20, samples=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM6Sl3f8PCat",
        "outputId": "00a9a4fc-76b2-40d1-f611-d50516f9ab59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8962468390922013"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binaryClassifierComplexity(model_100, sampler, trials=20, samples=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XzgelWIPDir",
        "outputId": "1fd20631-3e77-4c8b-efd3-61d689e55dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3222902848864622"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binaryClassifierComplexity(model_100_10, sampler, trials=20, samples=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V-dNjMZrEwY",
        "outputId": "bc4b612f-64ae-4bec-d530-6cba4a5c2b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.432378231222114"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binaryClassifierComplexity(model_tree, sampler, trials=20, samples=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvtFYVVeJIJB",
        "outputId": "bc1fcfb8-e6bc-4d4a-f698-dee54fce5094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34.374701795783224"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = sampler.sample(10)"
      ],
      "metadata": {
        "id": "g-XWJdnSrGPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tree.fit(*ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sNAkI_jApW5",
        "outputId": "7e637a9d-e077-4440-e84e-f54987b368f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_tree.score(*ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFqFyevaApwV",
        "outputId": "bdd2ef27-997d-46c3-ff84-b231e5f67225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds[0] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXowRWrCBXap",
        "outputId": "6ffb414b-985a-4d7e-c8f2-8f9c1f8d28c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.39394108],\n",
              "       [0.46045414],\n",
              "       [0.09321846],\n",
              "       [0.0281672 ],\n",
              "       [0.79684971],\n",
              "       [0.26325962],\n",
              "       [0.7879565 ],\n",
              "       [0.35116863],\n",
              "       [0.02461956],\n",
              "       [0.57953887]])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "az-VKTeLC6T8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
